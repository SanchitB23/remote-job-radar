# =========================================
# Remote Job Radar Embedder - Environment Configuration
# =========================================
# Python FastAPI service for generating text embeddings using SentenceTransformers
# 
# Copy this file to .env (for development) and fill in your values.

# =========================================
# Environment
# =========================================
PYTHON_ENV=development

# =========================================
# Server Configuration (Optional)
# =========================================
# Port for the FastAPI server (default: 8000)
# Note: docker-compose maps this to port 1234 externally
# PORT=8000

# Host to bind to (default: 0.0.0.0 for Docker)
# HOST=0.0.0.0

# =========================================
# Machine Learning Model Configuration (Optional)
# =========================================
# SentenceTransformers model to use for generating embeddings
# Default is a lightweight model that works well for job matching

# Default model (384 dimensions, ~90MB):
MODEL_NAME=BAAI/bge-small-en-v1.5

# Alternative lightweight models:
# MODEL_NAME=intfloat/e5-small-v2                    # 384-d, ~90MB
# MODEL_NAME=Snowflake/snowflake-arctic-embed-xs    # 384-d, ~90MB
# MODEL_NAME=sentence-transformers/all-MiniLM-L6-v2 # 384-d, ~90MB

# Larger, more accurate models (requires more memory):
# MODEL_NAME=BAAI/bge-base-en-v1.5                  # 768-d, ~440MB
# MODEL_NAME=intfloat/e5-base-v2                    # 768-d, ~440MB

# =========================================
# Performance Configuration (Optional)
# =========================================
# Number of worker processes (default: auto-detected based on CPU cores)
# WORKERS=4

# Enable GPU acceleration if available (requires CUDA setup)
# USE_GPU=false

# Maximum batch size for processing multiple texts at once
# BATCH_SIZE=32

# =========================================
# Caching Configuration (Optional)
# =========================================
# Cache embeddings to improve performance for repeated requests
# ENABLE_CACHE=true
# CACHE_SIZE=1000

# Cache directory for storing model files
# CACHE_DIR=/tmp/embedder_cache

# =========================================
# Logging Configuration (Optional)
# =========================================
# Log level: DEBUG, INFO, WARNING, ERROR
LOG_LEVEL=INFO

# Enable structured JSON logging
# LOG_FORMAT=json

# =========================================
# Security Configuration (Optional)
# =========================================
# API key for securing the embedder service (if needed in production)
# API_KEY=your_secure_api_key_here

# Allowed origins for CORS (if serving web requests directly)
# ALLOWED_ORIGINS=http://localhost:3000,http://localhost:8080

# =========================================
# Resource Limits (Optional)
# =========================================
# Maximum text length to process (characters)
# MAX_TEXT_LENGTH=10000

# Request timeout in seconds
# REQUEST_TIMEOUT=30

# Maximum requests per minute per client (rate limiting)
# MAX_REQUESTS_PER_MINUTE=100
